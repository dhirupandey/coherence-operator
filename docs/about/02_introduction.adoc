///////////////////////////////////////////////////////////////////////////////

    Copyright (c) 2020, Oracle and/or its affiliates.
    Licensed under the Universal Permissive License v 1.0 as shown at
    http://oss.oracle.com/licenses/upl.

///////////////////////////////////////////////////////////////////////////////

= Coherence Operator Introduction

== What is the Coherence Operator?
The Coherence Operator is a https://kubernetes.io/docs/concepts/extend-kubernetes/operator/[Kubernetes Operator] that
is used to manage https://oracle.github.io/coherence[Oracle Coherence] clusters in Kubernetes.
The Coherence Operator takes on the tasks of that human Dev Ops resource might carry out when managing Coherence clusters,
such as configuration, installation, safe scaling, management and metrics.

The Coherence Operator is a Go based application built using the https://github.com/operator-framework/operator-sdk[Operator SDK].
It is distributed as a Docker image and Helm chart for easy installation and configuration.


== Coherence Clusters
A Coherence cluster is a number of distributed Java Virtual Machines (JVMs) that communicate to form a single coherent cluster.
In Kubernetes, this concept can be related to a number of Pods that form a single cluster. 
In each `Pod` is a JVM running a Coherence `DefaultCacheServer`, or a custom application using Coherence.

The operator uses a Kubernetes Custom Resource Definition (CRD) to represent a group of members in a Coherence cluster.
Typically, a deployment would be used to configure one or more members of a specific role in a cluster.
Every field in the `Coherence` CRD `Spec` is optional, so a simple cluster can be defined in  yaml as:

[source,yaml]
----
apiVersion: coherence.oracle.com/v1
kind: Coherence
metadata:
  name: my-cluster # <1>
----

<1> In this case the `metadata.name` field in the `Coherence` resource yaml will be used as the Coherence cluster name.

The operator will use default values for fields that have not been entered, so the above yaml will create
a Coherence deployment using a `StatefulSet` with a replica count of three, which means that will be three storage
enabled Coherence `Pods`.

See the <<about/04_coherence_spec.adoc,Coherence CRD spec>> page for details of all the fields in the CRD.

In the above example no `spec.image` field has been set, so the Operator will use a publicly pullable Coherence CE
image as its default. These images are meant for demos, POCs and experimentation, but for a production application you
should build your own image.


== Using Commercial Coherence Versions

NOTE: Whilst the Coherence CE version can be freely deployed anywhere, if your application image uses a commercial
version of Oracle Coherence then you are responsible for making sure your deployment has been properly licensed.

Oracle's current policy is that a license will be required for each Kubernetes Node that images are to be pulled to.
While an image exists on a node it is effectively the same as having installed the software on that node.

One way to ensure that the Pods of a Coherence deployment only get scheduled onto nodes that meet the
license requirement is to configure Pod scheduling, for example a node selector. Node selectors, and other scheduling,
is simple to configure in the `Coherence` CRD, see the <<other/090_pod_scheduling.adoc,scheduling documentation>>

For example, if a commercial Coherence license exists such that a sub-set of nodes in a Kubernetes cluster
have been covered by the license then those nodes could all be given a label, e.g. `coherenceLicense=true`

When creating a `Coherence` deployment specify a node selector to match the label:

[source,yaml]
----
apiVersion: coherence.oracle.com/v1
kind: Coherence
metadata:
  name: test
spec:
  image: my-app:1.0.0         # <1>
  nodeSelector:
    coherenceLicense: 'true'  # <2>
----

<1> The `my-app:1.0.0` image contains a commercial Coherence version.
<2> The `nodeSelector` will ensure Pods only get scheduled to nodes with the `coherenceLicense=true` label.

There are other ways to configure Pod scheduling supported by the Coherence Operator (such as taints and tolerations)
and there are alternative ways to restrict nodes that Pods can be schedule to, for example a namespace in kubernetes
can be restricted to a sub-set of the cluster's nodes. Using a node selector as described above is probably the
simplest approach.

